# Часть 3. Технология Ethernet

---

## 1. Назовите преимущества и недостатки разделяемой среды.

**Разделяемая среда** — это среда передачи данных (например, коаксиальный кабель, шина Ethernet), которую одновременно могут
использовать несколько сетевых интерфейсов (устройств) для передачи информации, однако в каждый конкретный момент времени
передавать данные может только один узел.

### Преимущества разделяемой среды
1. **Простота и низкая стоимость**
    - Требуется минимум оборудования: один общий сегмент кабеля (шина или концентратор‑хаб - сетевое устройство для 
   объединения компьютеров в локальную сеть Ethernet с помощью кабелей (чаще — витой пары)).
    - Не нужны сложные коммутаторы или маршрутизаторы.
2. **Лёгкость настройки**
    - Добавление новых узлов не требует сложной конфигурации — достаточно физического подключения к среде.
3. **Наглядность топологии**
    - Физическая структура сети проста для понимания и диагностики (особенно в классических топологиях «шина» или «звезда» с хабом).

### Недостатки разделяемой среды
1. **Коллизии и снижение производительности**
    - Все узлы делят одну среду передачи: при одновременной отправке данных возникает коллизия (конфликт).
    - Протокол CSMA/CD (это механизм «вежливого общения» в старых Ethernet‑сетях: устройства сначала слушают,
   при конфликте останавливаются, ждут и пробуют заново. Сегодня заменён более эффективными технологиями.) вынужден повторно
   передавать кадры, что снижает реальную пропускную способность.
2. **Ограниченная масштабируемость**
    - Чем больше узлов, тем чаще коллизии → скорость падает. Типичные лимиты: до 30–50 узлов в сегменте.
3. **Низкая безопасность**
    - Любой узел может «слушать» трафик всего сегмента (пассивный перехват пакетов).
4. **Единая точка отказа**
    - Повреждение общего кабеля или хаба выводит из строя всю сеть.
5. **Фиксированная скорость**
    - Все устройства работают на одной скорости (например, 10 Мбит/с в классическом Ethernet), что мешает гибкому апгрейду
   отдельных узлов.

Разделяемая среда экономична для малых сетей, но не подходит для высоконагруженных и безопасных сценариев из‑за коллизий,
ограничений масштабирования и рисков перехвата трафика.

---

## 2. Верно ли утверждение: «Маркерный доступ обеспечивает более эффективное использование пропускной способности разделяемой среды»?

Ответ верно

Маркерный доступ (например, в технологии Token Ring) обеспечивает более эффективное использование пропускной способности 
разделяемой среды за счёт:
* **Циклической передачи маркера** — право на передачу данных передаётся от станции к станции по кольцу;
* **Ограничения времени удержания маркера** (тайм-аут) — станция обязана передать маркер дальше, если не использует его;
* **Алгоритма раннего освобождения маркера** (Early Token Release) — станция передаёт маркер следующей станции сразу после
окончания передачи бита кадра, не дожидаясь подтверждения приёма. Это позволяет использовать пропускную способность до 80%
от номинальной;
* **Механизма приоритетов** для разных видов сообщений — повышает эффективность использования среды.

---

## 3. К какому типу относится МАС-адрес 02:25:86:64:са:е4?

MAC-адрес **02:25:86:64:ca:e4** относится к типу **«индивидуальный локальный»** (Unicast), потому что:
1. **Индивидуальный** — это уникальный 48-битный (6-байтный) идентификатор конкретного сетевого устройства (например, сетевой карты),
присвоенный производителем. Первые 3 байта (OUI — Organizationally Unique Identifier, например, **02:25:86**) указывают 
на производителя, а последние 3 байта (**64:ca:e4**) — уникальный номер устройства.
2. **Локальный** — работает только в пределах локальной сети (LAN), используется на канальном уровне модели OSI (уровень 2)
для доставки кадров конкретному устройству. Не маршрутизируется за пределы локальной сети (в отличие от IP-адреса).
3. **Unicast-адрес** — предназначен для адресации одного устройства (в противовес Multicast и Broadcast-адресам, которые
рассчитаны на группы или все устройства сети).

Это уникальный «паспорт» устройства в локальной сети, «прошитый» на заводе и неизменяемый (за редкими исключениями).
Используется для точной доставки данных внутри LAN.

---

## 4. Преамбула в кадре Ethernet нужна для (выберите вариант ответа):</br>а) вхождения приёмника в синхронизм;</br>б) вхождения передатчика в синхронизм;</br>в) расширения кадра для более устойчивого распознавания коллизий.

Ответ а)

**Пояснение:**  
Преамбула в кадре Ethernet — это последовательность из 7 байт (01010101…), за которой следует байт‑разделитель (10101011). 
Её ключевая задача — дать приёмнику время:
- настроиться на тактовую частоту передатчика;
- синхронизировать свои внутренние часы с потоком входящих битов;
- подготовиться к корректному приёму и интерпретации последующих полей кадра (адреса назначения, данных и т.д.).

**Почему не подходят другие варианты:**
- **б)** передатчик изначально контролирует свой сигнал — ему синхронизация с самим собой не требуется;
- **в)** преамбула не влияет на распознавание коллизий: для этого служат иные механизмы (например, CSMA/CD в классических
разделяемых средах Ethernet).

---

## 5. При повышении скорости передачи данных максимальный диаметр сети Ethernet на разделяемой среде (выберите вариант ответа):</br>а) увеличивается;</br>б) уменьшается;</br>в) остаётся неизменным.

Ответ б)

В сетях Ethernet на разделяемой среде действует жёсткое ограничение на максимальный диаметр сети — он напрямую связан с 
механизмом обнаружения коллизий (CSMA/CD). Чтобы коллизия корректно распознавалась всеми узлами, сигнал должен успеть 
пройти до самого дальнего узла и вернуться обратно *до того*, как станция завершит передачу кадра.

При **увеличении скорости передачи** биты следуют друг за другом быстрее. Это означает, что:
- станция успевает передать больше данных за тот же промежуток времени;
- окно обнаружения коллизий сужается: если сигнал не вернётся вовремя, узел не поймёт, что произошла коллизия, — и кадр 
будет потерян.

Чтобы гарантировать своевременное обнаружение коллизий, приходится **сокращать максимальную длину сегментов** (т.е. уменьшать
диаметр сети).

**Пример:**
- для 10 Mbps Ethernet (классический коаксиальный/хабовый Ethernet) допустимый диаметр ~2 500 м (с учётом повторителей);
- для 100 Mbps (Fast Ethernet) — уже ~205 м;
- для 1 Gbps (Gigabit Ethernet) в полудуплексном режиме — порядка 25 м.

Таким образом, рост скорости требует уменьшения физического размера сети для сохранения работоспособности CSMA/CD.

---

## 6. Для повышения производительности сети Ethernet количество её сегментов (при сохранении числа станций в сети) нужно (выберите вариант ответа):</br>а) увеличить;</br>б) уменьшить.

Ответ а)

При делении сети Ethernet на большее число сегментов (провод) (с сохранением общего количества станций) достигается:

- **снижение нагрузки на каждый отдельный сегмент:** число узлов в одном сегменте уменьшается, что сокращает вероятность
коллизий (по механизму CSMA/CD);
- **уменьшение размера домена коллизий:** в каждом сегменте формируется свой домен коллизий — меньше устройств конкурирует
за доступ к среде;
- **сокращение времени ожидания доступа:** станции быстрее получают возможность передавать данные, так как «соперников»
в сегменте стало меньше;
- **рост полезной пропускной способности:** за счёт снижения доли трафика, потерянного из‑за коллизий и повторных передач.

Для объединения сегментов используют устройства канального уровня (коммутаторы, мосты), которые изолируют 
домены коллизий друг от друга. В результате общая производительность сети повышается даже при неизменном числе станций.

---

## 7. Таблица продвижения моста имеет следующий вид:
| МАС-адрес         | Порт    |
|-------------------|---------|
| f8:f2:1e:0c:3a:b8 | 1       |
| d8:94:66:4c:37:bf | 2       |
## На порт 2 коммутатора поступает кадр с адресом назначения ac:1f:6b:64:c7:d6 и адресом источника f8:f2:1e:0c:3a:b8. Укажите, какое действие выполнит мост:</br>а) отбросит кадр;</br>б) передаст его на все порты и заменит первую запись таблицы продвижения на МАС-адрес f8:f2:1e:0c:3a:b8, Порт 2;</br>в) передаст его на все порты и не станет корректировать записи.

Ответ в)

**Обоснование по шагам:**
1. **Анализ адреса назначения (`ac:1f:6b:64:c7:d6`)**
   - Мост сверяет MAC‑адрес назначения с таблицей продвижения.
   - В таблице нет записи для `ac:1f:6b:64:c7:d6`.
   - **Вывод:** мост не знает, к какому порту подключён получатель → выполняет **flooding** (рассылает кадр *на все порты,
   кроме того, откуда он пришёл*).
2. **Анализ адреса источника (`f8:f2:1e:0c:3a:b8`)**
   - В таблице уже есть запись: `f8:f2:1e:0c:3a:b8 → Порт 1`.
   - Поступающий кадр пришёл через **Порт 2**.
   - Однако мост **не заменяет** существующую запись автоматически при таком расхождении. Стандартное поведение:
      - если адрес источника уже есть в таблице, мост *оставляет запись без изменений* (считая её актуальной);
      - обновление происходит лишь при явных признаках перемещения (в ряде реализаций — по истечении таймера старения),
     но не по единичному кадру.
3. **Итог**
   - Кадр отправляется методом flooding (на все порты кроме Порта 2).
   - Записи в таблице остаются прежними.

**Почему не подходят другие варианты:**
- **а)** мост не отбрасывает кадр: отсутствие адреса назначения в таблице — это основание для flooding, а не для удаления.
- **б)** мост не заменяет существующую запись для источника: наличие старой записи (`Порт 1`) блокирует её мгновенное 
обновление на `Порт 2` по умолчанию.

---

## 8. В сети на коммутаторах образовалась петля. Укажите, с помощью каких мер можно предотвратить негативные последствия такой конфигурации:</br>а) установить более скоростные порты Ethernet;</br>б) активировать протокол STP;</br>в) разорвать петлю физическим отсоединением порта;</br>г) разорвать петлю логическим переводом порта в неактивное состояние.

Ответ б), в)

**Суть проблемы**  
При наличии петли в сети Ethernet возникают:
- **широковещательный шторм** (broadcast storm): кадры бесконечно циркулируют по кольцу;
- **дублирование кадров**: один и тот же кадр приходит на разные порты;
- **перегрузка коммутаторов** и полная неработоспособность сети.

**б) активировать протокол STP** — **верно**.  
Протокол Spanning Tree Protocol (STP, IEEE 802.1D) разработан специально для борьбы с петлями. Он:
- автоматически блокирует избыточные связи, оставляя только один активный путь между узлами;
- переводит «лишние» порты в состояние *Blocking* (блокировка);
- при обрыве основного пути автоматически активирует резервный.  
  Это **программное, управляемое** решение — наиболее профессиональный способ.
**в) разорвать петлю физическим отсоединением порта** — **верно**.  
Простое механическое отключение одного из кабелей, образующих кольцо, физически устраняет петлю. Это:
- самый быстрый способ аварийного восстановления работоспособности сети;
- надёжное решение, не требующее настройки оборудования.  
  Минус — нет резервирования; если останется только один путь, его обрыв приведёт к разрыву связи.

### Почему не подходят остальные варианты
**а) установить более скоростные порты Ethernet** — **неверно**.  
Увеличение скорости передачи не устраняет причину проблемы. Петля по‑прежнему будет генерировать бесконечный поток кадров;
просто они будут передаваться быстрее. Сеть всё равно выйдет из строя.
**г) разорвать петлю логическим переводом порта в неактивное состояние** — **частично верно, но избыточно**.  
Технически это работает (порт не пропускает трафик — петля разрывается), но:
- требует ручной настройки на каждом коммутаторе;
- не обеспечивает автоматического восстановления при сбоях;
- по сути, дублирует действие STP, но без его интеллектуальных механизмов.  
  STP (**б**) делает то же самое *автоматически* — поэтому он предпочтительнее.

---

## 9. Чем отличаются коммутаторы Bare Metal от White Box?

**Bare Metal коммутаторы**
- Поставляются **без операционной системы** (нет сетевой ОС).
- Оснащены лишь базовым загрузчиком (например, ONIE — Open Network Install Environment), который позволяет установить ОС вручную.
- Покупатель самостоятельно выбирает и устанавливает сетевую ОС (например, Cumulus Linux, Big Switch Light OS, PicOS или собственную разработку).
- Типичные производители: тайваньские и российские ODM‑поставщики (Accton, Edge‑Core и др.).
- **Ключевая особенность:** полная независимость ПО от «железа» — заказчик сам комбинирует аппаратную платформу и софт.

**White Box коммутаторы**
- Представляют собой **готовый пакет**: аппаратная платформа + предустановленная сетевая ОС.
- ОС может быть от стороннего разработчика (Cumulus Linux, PicOS) либо от самого поставщика (например, Juniper OCX1100 с JUNOS).
- Не требуют ручной установки ОС: устройство готово к настройке сразу после включения.
- Часто дешевле традиционных брендовых решений (на 30–40% по данным Dell’Oro Group).
- **Ключевая особенность:** баланс гибкости и простоты — ОС уже есть, но она не «привязана» к вендору «железа».

### Ключевые отличия (итог)
- **Наличие ОС:** у Bare Metal её нет (только загрузчик), у White Box — уже установлена.
- **Готовность к работе:** Bare Metal требует ручной установки ПО; White Box можно настраивать сразу.
- **Гибкость:** Bare Metal даёт максимальную свободу выбора ОС; White Box предлагает «пакетное» решение.
- **Целевая аудитория:** Bare Metal — для крупных компаний с собственными разработчиками ПО (например, Facebook, Google);
White Box — для ЦОД и организаций, которым нужна экономия без потери функциональности.

---

## 10. Поясните, для чего в стандарте Gigabit Ethernet введено поле расширения:</br>а) для увеличения доли пользовательских данных в кадре;</br>б) для обеспечения диаметра сети 200 м при работе на разделяемой среде.

Ответ б)

Поле расширения (extension field, или *carrier extension*) в Gigabit Ethernet введено **для корректной работы механизма CSMA/CD**
в полудуплексном режиме. Разберу суть вопроса пошагово.

1. **Проблема при росте скорости**  
   В Gigabit Ethernet скорость передачи данных в 10 раз выше, чем в классическом 10 Mbps Ethernet. Это значит, что кадр 
минимальной длины (64 байта) передаётся во много раз быстрее.
2. **Требование CSMA/CD**  
   Чтобы механизм обнаружения коллизий работал, станция должна успеть *заметить* коллизию *до завершения передачи кадра*.
Иначе кадр будет потерян, а коллизия не распознана.
3. **Физический предел — время двойного оборота (PDV)**  
   Сигнал должен успеть дойти до самого дальнего узла и вернуться обратно (время PDV). При увеличении скорости это окно
резко сужается. Без мер компенсации допустимый диаметр сети сократился бы до ~25 м — что неприемлемо.
4. **Решение — поле расширения**
    - Если кадр короче 512 байт, к нему дописывают «пустые» байты (расширение), доводя общую длину до 512 байт.
    - Это искусственно *удлиняет передачу*, давая сигналу время пройти по сети и вернуться при коллизии.
    - Приёмник игнорирует байты расширения — они не попадают в полезную нагрузку.
5. **Результат**  
   Благодаря расширению удаётся сохранить диаметр сети ~200 м в полудуплексных сегментах Gigabit Ethernet — сопоставимо с
Fast Ethernet (100 Mbps).

**Почему не подходит вариант а)**  
Поле расширения *не увеличивает* долю пользовательских данных. Наоборот, оно добавляет служебные байты, которые не несут
полезной информации. Цель — не оптимизация полезной нагрузки, а сохранение работоспособности CSMA/CD на больших расстояниях.

---

## 11. Существует ли вариант стандарта 10G Ethernet на витой паре?

Да, такой стандарт существует.

Это **10GBASE‑T** (стандарт **IEEE 802.3an‑2006**).

**Ключевые параметры:**
- скорость передачи: 10 Гбит/с;
- среда передачи: витая пара категории 6a или 7;
- максимальная длина сегмента:
    - до 55 м — на кабеле Cat6;
    - до 100 м — на кабеле Cat6a или Cat7;
- используется все 4 пары проводов в кабеле;
- применяется сложная модуляция (PAM‑16 с DSQ128) для достижения высокой скорости по медному кабелю.

**Важные нюансы:**
- требует более качественного кабеля и разъёмов, чем 1Gbit/s‑решения;
- энергопотребление выше, чем у оптических вариантов 10G Ethernet;
- широко применяется в локальных сетях (LAN), ЦОД и корпоративных инфраструктурах, где уже проложена витая пара и нет 
необходимости переходить на оптоволокно.

---

## 12. Поясните, за счёт чего повышена скорость в стандарте 100GBase-SR4 по сравнению со стандартом 10GBase-SR (выберите вариант ответа):</br>а) применения метода кодирования 16-QAM;</br>б) повышения тактовой частоты в 4 раза;</br>в) повышения тактовой частоты в 2,5 раза;</br>г) применения четырёх параллельных потоков.

Ответ в), г)

### Как работает 100GBASE‑SR4
Стандарт **100GBASE‑SR4** обеспечивает скорость 100 Гбит/с за счёт комбинации двух решений:
1. **Четыре параллельных потока (ответ г)**
    - Используется **4 отдельных оптических канала** (волокна или пары в многомодовом кабеле).
    - Каждый канал передаёт поток **25 Гбит/с**.
    - На приёмной стороне потоки объединяются: 4 * 25 Гбит/с = 100 Гбит/с.
    - Это ключевой архитектурный сдвиг: вместо одного канала (как в 10GBASE‑SR) — четыре.
2. **Повышение тактовой частоты (ответ в)**
    - В **10GBASE‑SR** один канал работает на скорости **10 Гбит/с**.
    - В **100GBASE‑SR4** каждый из четырёх каналов работает на **25 Гбит/с**.
    - То есть скорость *на канал* выросла в 2.5 раза: 25 / 10 = 2.5.
    - Эта более высокая тактовая частота внутри канала — необходимое техническое условие для достижения 25 Гбит/с на поток.

### Почему остальные варианты не подходят
- **а) метод кодирования 16‑QAM**  
  Не используется в оптических SR‑стандартах. 16‑QAM применяется в *медных* вариантах Ethernet (например, 10GBASE‑T) для
уплотнения данных в полосе частот кабеля. В SR4 используется простая **NRZ‑модуляция** (Non‑Return‑to‑Zero).

- **б) повышение тактовой частоты в 4 раза**  
  Если бы частота выросла в 4 раза, один канал дал бы 40 Гбит/с (10 * 4), а не 25 Гбит/с. Это противоречит спецификации SR4.

---

## 13. Поясните, какие механизмы позволили достичь требуемой скорости в стандарте 400G Ethernet (выберите вариант ответа):</br>а) кодирование PAM4;</br>б) кодирование PAM5;</br>в) применение параллельных волн;</br>г) применение кодов FEC.

Ответ а), в), г)

1. **а) Кодирование PAM4**
    - **Что это.** PAM4 (Pulse Amplitude Modulation, 4‑уровневая) передаёт **2 бита за один символ** (уровни: −3, −1, +1,
   +3) вместо 1 бита у традиционного NRZ.
    - **Эффект.** Удваивает спектральную эффективность: при той же тактовой частоте скорость удваивается.
    - **В 400G.** Ключевой элемент в стандартах типа 400GBASE‑DR4, где сочетается с параллелизмом.
2. **в) Применение параллельных волн (параллельных каналов)**
    - **Суть.** Данные разбиваются на несколько независимых потоков (оптических или электрических), передаваемых одновременно.
    - **Примеры:**
        - 4×100 Гбит/с (например, 400GBASE‑SR8 использует 8 пар волокон);
        - 8×50 Гбит/с и т.п.
    - **Выигрыш.** Суммарная скорость складывается из скоростей всех каналов.
    - **Технологии.** WDM (спектральное уплотнение, объединение нескольких разных световых сигналов в один пучек), многоволоконные
   кабели, многополосные электрические интерфейсы.
3. **г) Применение кодов FEC (Forward Error Correction -  это технология исправления ошибок в процессе передачи данных 
без необходимости повторной отправки пакета)**
    - **Что это.** FEC добавляет избыточные биты для обнаружения и *исправления ошибок* на приёмной стороне без повторной
   передачи.
    - **Зачем в 400G.** При высоких скоростях и использовании PAM4 растёт вероятность ошибок из‑за шума и искажений. FEC 
   компенсирует это, сохраняя приемлемый BER (Bit Error Rate - это показатель качества передачи данных, выраженный долей
   ошибочных битов среди всех переданных.).
    - **Стандарт.** В 400G применяется мощный FEC (например, Reed‑Solomon RS(544,514)), что критично для работы на реальных
   линиях.

### Почему исключён вариант б) кодирование PAM5
- **PAM5 не используется** в стандартах 400G Ethernet.
- **Причины:**
    - PAM5 передаёт 2,32 бита на символ — прирост лишь на ~16% относительно PAM4, но требует значительно более сложной 
  обработки и чувствителен к шуму;
    - IEEE 802.3 выбрал PAM4 как баланс между скоростью, сложностью и надёжностью;
    - в экосистеме 400G нет утверждённых стандартов с PAM5.

---

## 14. Каким образом можно назначить некоторый коммутатор корневым?

Чтобы назначить коммутатор корневым в сети Ethernet, нужно явно задать ему наименьший приоритет в протоколе STP (Spanning
Tree Protocol).

В сетях с избыточными связями используется протокол STP для построения древовидной топологии без петель. Он выбирает
**корневой коммутатор** (root bridge) — центральную точку, от которой строится дерево. По умолчанию выбор идёт автоматически
(на основе MAC‑адреса и приоритета), но его можно контролировать.

Чтобы принудительно сделать конкретный коммутатор корневым:
1. **Задайте ему минимальный приоритет.** Стандартное значение приоритета — 32768. Чтобы коммутатор гарантированно стал 
корневым, установите приоритет **ниже** этого числа (например, 0 или 4096).  
   Формат команды (для типичных управляемых коммутаторов):
   ```
   spanning-tree vlan <номер_VLAN> priority <значение>
   ```  
   Например:  
   `spanning-tree vlan 1 priority 4096`
2. **Альтернативный способ — команда `root`.** Некоторые вендоры (например, Cisco) предлагают упрощённую команду для 
автоматического выставления оптимального приоритета:
   ```
   spanning-tree root primary
   ```  
   Это неявное задание минимального приоритета, достаточного для победы в выборе корня.

**Почему это работает:**  
STP выбирает корневой коммутатор по **наименьшему Bridge ID**, который состоит из:
- приоритета (настраиваемый параметр);
- MAC‑адреса (аппаратная характеристика).

Снижая приоритет, вы делаете Bridge ID коммутатора «меньше» всех остальных — протокол автоматически назначает его корневым.

---

## 15. Верно ли утверждение: «порт, имеющий минимальное расстояние до корневого коммутатора среди всех портов данного коммутатора, является назначенным»?

Ответ нет

### Ключевые термины
- **Корневой порт** (*root port*) — у *некорневого* коммутатора: единственный порт, обеспечивающий кратчайший путь к 
корневому коммутатору. Есть ровно один на коммутатор (если сам коммутатор не является корневым).
- **Назначенный порт** (*designated port*) — порт сегмента (участка сети между коммутаторами/устройствами), который обеспечивает
наилучший путь *из этого сегмента* к корневому коммутатору. По одному на сегмент.

### Почему утверждение ошибочно
1. **Разные объекты сравнения.**
   - Корневой порт выбирается *внутри коммутатора*: среди его собственных портов ищется тот, что ведёт к корню с наименьшей
   стоимостью пути.
   - Назначенный порт выбирается *для сегмента*: из всех портов, подключённых к данному сегменту, выбирается один «лучший» 
   (по стоимости пути к корню).
2. **Местоположение.**
   - Корневой порт всегда находится на *некорневом* коммутаторе.
   - Назначенный порт может быть и на корневом коммутаторе (все его порты — назначенные), и на некорневом (если его путь 
   к корню через этот сегмент оптимален).
3. **Функция.**
   - Корневой порт *ведёт к корню*.
   - Назначенный порт *принимает трафик из сегмента* и передаёт его дальше по направлению к корню.

### Пример для ясности
Пусть есть цепочка:  
`Корневой коммутатор А` — `Сегмент 1` — `Коммутатор B` — `Сегмент 2` — `Коммутатор C`.
- На коммутаторе B:
   - Корневой порт — тот, что смотрит на `А` (минимальное расстояние до корня).
   - Назначенный порт для `Сегмента 2` — тот, что смотрит на `C` (обеспечивает путь из этого сегмента к корню).
- На коммутаторе C:
   - Корневой порт — тот, что смотрит на `B` (кратчайший путь к корню).
   - Нет назначенных портов (если нет других сегментов), т.к. для `Сегмента 2` назначенный порт уже на `B`.

---

## 16. Протокол RSTP находит покрывающее дерево быстрее протокола STP, так как он (выберите вариант ответа):</br>а) исключает из рассмотрения тупиковые порты;</br>б) принимает во внимание существующие VLAN;</br>в) назначает резервные порты для корневых и назначенных портов;</br>г) сокращает период фиксации отказа в сети.

Ответы а), в), г)

**а) Исключает из рассмотрения тупиковые порты**
- В RSTP порты, подключённые к конечным устройствам (ПК, принтеры и т.п.), переводятся в состояние **Edge Port** (аналог PortFast в STP).
- Такие порты сразу переходят в состояние *Forwarding* (передача данных), минуя задержки.
- Это ускоряет сходимость сети: не нужно ждать таймеров.
**в) Назначает резервные порты для корневых и назначенных портов**
- RSTP вводит понятие **резервных** (*backup*) и **альтернативных** (*alternate*) портов:
   - *Альтернативный порт* — запасная линия к корневому коммутатору (готова включиться при отказе корневого порта).
   - *Резервный порт* — дублирующий путь в том же сегменте (на случай отказа назначенного порта).
- При сбое переключение происходит почти мгновенно — не требуется пересчёт дерева.
**г) Сокращает период фиксации отказа в сети**
- В STP отказ порта детектируется через таймаут (обычно 20 с — *Max Age*).
- В RSTP используется механизм **согласования** (*proposal/agreement*): коммутаторы «договариваются» о ролях портов за миллисекунды.
- Отказ фиксируется быстрее: вместо таймеров — обмен BPDU‑пакетами.
- Результат: сходимость сети сокращается с 30–50 с (STP) до 1–6 с (RSTP).

**б) Принимает во внимание существующие VLAN**
- Учёт VLAN относится к другим протоколам (например, **MSTP** — Multiple Spanning Tree Protocol).
- И STP, и базовый RSTP работают на уровне всей сети, а не по отдельным VLAN.

### Почему RSTP в целом быстрее
Ключевые улучшения RSTP над STP:
1. **Мгновенный переход Edge‑портов** в Forwarding.
2. **Готовность резервных путей** (alternate/backup порты).
3. **Динамическое согласование** вместо ожидания таймеров.
4. **Чёткие состояния портов** (Discarding → Learning → Forwarding) без лишних фаз.

---

## 17. Составьте список доступа, запрещающий узлу с МАС-адресом f8:f2:1e:0c:3a:b8 обращаться к узлу с МАС-адресом ac:1f:6b:64:c7:d6, при этом все остальные взаимодействия в сети должны быть разрешены.

```
mac access-list extended BLOCK_MAC
 deny host f8:f2:1e:0c:3a:b8 host ac:1f:6b:64:c7:d6
permit any any
```

1. **Создание списка**  
   `mac access-list extended BLOCK_MAC`
   - `mac access-list` — команда для создания MAC‑списка;
   - `extended` — тип списка, позволяющий фильтровать по паре «источник → назначение»;
   - `BLOCK_MAC` — имя списка (можно выбрать любое).
2. **Запрет конкретного трафика**  
   `deny host f8:f2:1e:0c:3a:b8 host ac:1f:6b:64:c7:d6`
   - `deny` — действие «запретить»;
   - `host` перед первым MAC — указывает, что источник *точно* этот адрес;
   - `f8:f2:1e:0c:3a:b8` — MAC‑адрес узла‑источника;
   - `host` перед вторым MAC — указание на *точное* назначение;
   - `ac:1f:6b:64:c7:d6` — MAC‑адрес узла‑получателя.  
     → Правило блокирует *только* пакеты от первого узла ко второму.
3. **Разрешение всего остального**  
   `permit any any`
   - `permit` — действие «разрешить»;
   - `any any` — любые MAC‑адреса источника и назначения;  
     → Все прочие комбинации MAC‑адресов проходят без ограничений.

### Важные нюансы
- **Применение списка**  
  Сам по себе список ничего не делает. Его нужно **привязать к интерфейсу** (или VLAN), где требуется фильтрация:
  ```
  interface GigabitEthernet 0/1
  mac access-group BLOCK_MAC in
  ```  
   - `in` — фильтр применяется к входящему трафику на порту.
- **Порядок правил**  
  Коммутатор проверяет правила **последовательно**. Если первое правило (`deny`) сработало — пакет отбрасывается. 
Если нет — идёт проверка следующего (`permit`). Поэтому важно ставить запреты *выше* разрешений.
- **Чувствительность к регистру**  
  MAC‑адреса можно писать в любом регистре (например, `F8:F2:1E:0C:3A:B8` тоже сработает).
- **Формат записи MAC**  
  Некоторые устройства принимают MAC в форматах:
   - `f8-f2-1e-0c-3a-b8`;
   - `f8f2.1e0c.3ab8`.  
     Уточните формат для вашего оборудования.

---

## 18. Сервер и клиентский компьютер подключены к портам одного и того же коммутатора: сервер — к порту Ethernet 10G, а клиент — к порту Ethernet 1G. На клиенте работает только одно приложение, которое обращается к серверу. Повысится ли скорость обмена клиента с сервером, если клиенту добавить ещё один порт Ethernet 1G, соединяющий его с коммутатором, и образовать группу LAG из двух его портов Ethernet 1G?

Ответ нет

Причина — в **узком месте (bottleneck)** на стороне сервера:

- сервер подключён к порту **10 G**;
- клиент изначально подключён к порту **1 G**;
- даже с двумя портами **1 G** в LAG‑группе суммарная пропускная способность клиента — максимум **2 G**.

Но трафик между клиентом и сервером проходит **через один и тот же путь**: клиент → коммутатор → сервер. При этом:
- порт сервера (10 G) способен принимать до 10 Гбит/с;
- но порт клиента (даже в LAG) даёт максимум 2 Гбит/с.

**Итог:** сервер *может* принять больше, но клиент *не может* передать больше 2 Гбит/с. Реальная скорость ограничена **исходящей**
пропускной способностью клиента.

### Почему LAG не помогает в этом сценарии
LAG (Link Aggregation Group) распределяет трафик **между параллельными потоками**, а не ускоряет один поток. Важные нюансы:
1. **Одно приложение = один TCP‑поток**  
   Если на клиенте работает только одно приложение, оно, как правило, создаёт **один TCP‑сеанс**. LAG не может разбить один
поток на два порта — весь трафик пойдёт через **один** из портов группы. Второй останется незадействованным.
2. **Балансировка работает на уровне потоков**  
   LAG покажет эффект, только если есть **множество независимых потоков** (например, несколько клиентов или несколько приложений).
Тогда часть потоков пойдёт через первый порт, часть — через второй. В вашем случае такого нет.
3. **Ограничение коммутатора**  
   Даже если бы LAG мог делить один поток, коммутатор всё равно не сможет передать от клиента к серверу больше, чем позволяет
клиентская сторона (2 Гбит/с максимум). Серверский порт 10 G здесь избыточен.

### Когда LAG дал бы прирост
Прирост скорости был бы возможен, если:
- клиент генерирует **много параллельных потоков** (несколько приложений/клиентов);
- сервер тоже подключён через LAG (чтобы принимать трафик параллельно);
- коммутатор корректно балансирует потоки между портами.

### Вывод
Добавление второго порта 1 G и создание LAG **не увеличит скорость** обмена между этим клиентом и сервером, потому что:
1. Один TCP‑поток не делится между портами LAG.
2. Пропускная способность клиента (2 Гбит/с) всё равно ниже возможностей сервера (10 Гбит/с).
3. Узкое место — исходящий трафик с клиента, а не приём на сервере.

---

## 19. Каким образом можно предотвратить включение некоторого порта в группу LAG протоколом LACP?

Чтобы порт не включался в LAG через LACP, нужно **отключить на нём протокол LACP** либо явно исключить из группы агрегации.

### Основные способы
1. **Отключить LACP на порту**  
   На большинстве коммутаторов это делается командой:
   ```
   interface <идентификатор_порта>
   no lacp enable
   ```  
   Или (в зависимости от вендора):
   ```
   lacp mode off
   ```  
   → Порт перестаёт обмениваться LACPDU‑пакетами, поэтому не может быть включён в LAG по LACP.
2. **Не добавлять порт в группу LAG**  
   Если порт не указан в конфигурации `port‑channel` / `channel‑group`, он автоматически остаётся вне агрегации. Пример:
   ```
   interface port-channel 1          # группа LAG 1
   interface GigabitEthernet 0/1       # порт, включённый в LAG
   channel-group 1 mode active        # привязан к группе 1
   interface GigabitEthernet 0/2       # другой порт
   # отсутствует channel-group — не участвует в LAG
   ```
3. **Настроить статический LAG (без LACP)**  
   Если группа агрегации создана в **статическом режиме**, LACP игнорируется. Порт попадёт в LAG только при явном указании
в конфигурации. Команда:
   ```
   interface port-channel <номер>
   mode manual
   ```  
   → LACP не активируется, даже если включён на порту.
4. **Задать несовместимые параметры**  
   LACP автоматически исключает порт из LAG, если его настройки **не совпадают** с остальными членами группы. Примеры:
   - разная скорость (например, 1 Гбит/с vs 10 Гбит/с);
   - разный режим дуплекса;
   - несовпадающие VLAN или QoS‑политики.  
     → Протокол отклонит порт при согласовании.

### Важные нюансы
- **Режим `passive` ≠ отключение.** В режиме `lacp mode passive` порт *может* присоединиться к LAG, если соседний коммутатор
инициирует согласование (`active`). Для полного исключения нужен именно `off` / `no lacp enable`.
- **Проверка состояния.** Убедиться, что порт исключён, можно командами:
   - `show lacp neighbors` (не должен отображаться в списке);
   - `show etherchannel summary` (не входит в группу).
- **Вендорные отличия.** Синтаксис команд может различаться (Cisco, Huawei, Juniper и т.д.), но логика одна:
**нет LACP → нет включения в LAG**.


### Итог
Чтобы порт **не включался** в LAG через LACP:
1. Отключите LACP напрямую (`no lacp enable` или `lacp mode off`).
2. Либо не добавляйте порт в `channel‑group` / `port‑channel`.
3. Либо настройте статический LAG (`mode manual`).
4. Либо сделайте его параметры несовместимыми с группой.

---

## 20. Поясните, каким образом можно объединить несколько VLAN (выберите вариант ответа):</br>а) с помощью маршрутизатора;</br>б) приписать их к одному транку.

Ответ а)

VLAN — это **сегменты на канальном уровне (L2)**. Устройства из разных VLAN *не видят друг друга* напрямую: они изолированы
на уровне Ethernet‑фреймов.

Чтобы разрешить обмен между ними, нужен **маршрутизатор (L3‑устройство)**:
- он принимает пакеты из одного VLAN;
- анализирует IP‑адреса назначения;
- перенаправляет трафик в другой VLAN согласно таблице маршрутизации.

Такой подход называется **inter‑VLAN routing**. Результат — VLAN *объединены* для обмена данными, но остаются логически 
изолированными (контроль через ACL, QoS и т.д.).

**Пример:**
- VLAN 10 (подсеть 192.168.10.0/24) — бухгалтерия;
- VLAN 20 (подсеть 192.168.20.0/24) — отдел кадров;
- маршрутизатор позволяет им общаться, но может блокировать отдельные сервисы (например, запретить доступ к файловому серверу бухгалтерии).

### Почему вариант б) неверен: транк не объединяет VLAN
**Транк** (trunk‑порт) — это канал, который **передаёт трафик нескольких VLAN через один физический порт** (с метками 802.1Q). Он:
- не снимает изоляцию между VLAN;
- лишь *транспортирует* их фреймы между коммутаторами или к маршрутизатору;
- сохраняет разделение на уровне L2.
**Что происходит:**
1. Коммутатор добавляет к фрейму тег VLAN ID.
2. Транк передаёт фреймы всех указанных VLAN на соседнее устройство.
3. Получатель (коммутатор/маршрутизатор) разбирает теги и направляет трафик в нужный VLAN.
→ VLAN остаются отдельными сегментами. Транк — это «труба», по которой они *соседствуют*, но не *объединяются*.
**Пример:**
- транк между коммутатором и маршрутизатором несёт VLAN 10, 20, 30;
- маршрутизатор (если настроен) объединит их;
- если маршрутизатора нет, устройства из VLAN 10 и VLAN 20 по‑прежнему не смогут общаться.

---

## 21. Какое действие выполняет порт доступа, передавая помеченный кадр клиентскому узлу (кадр получен от порта-транка по внутренней шине коммутатора)?

Порт доступа **удаляет тег VLAN** из кадра перед передачей клиентскому узлу.

### Почему это происходит
1. **Назначение портов**
    - **Порт‑транк** передаёт кадры *с тегами VLAN* (по стандарту 802.1Q) — для идентификации сегмента между 
   коммутаторами/маршрутизаторами.
    - **Порт доступа** (access port) предназначен для подключения *конечных узлов* (ПК, принтеров, IP‑камер и т.п.), 
   которые **не умеют обрабатывать теги VLAN**.
2. **Путь кадра**
    - Кадр приходит на коммутатор через транк — с тегом VLAN ID.
    - Коммутатор определяет по таблице MAC‑адресов, что получатель подключён к порту доступа.
    - Перед отправкой на порт доступа коммутатор **снимает тег** — преобразует помеченный кадр в обычный Ethernet‑кадр.
3. **Результат для узла**
    - Клиентский узел получает кадр *без каких‑либо меток*.
    - Устройство обрабатывает его как стандартный Ethernet‑пакет — без необходимости понимать VLAN.

### Обоснование
Это требование стандарта 802.1Q:
- тегирование нужно только внутри сети для разделения трафика;
- конечные узлы работают в «родной» сети (native VLAN) и не должны видеть служебные метки.

Если бы тег сохранялся, большинство клиентских устройств:
- проигнорировали бы кадр как некорректный;
- или не смогли бы его обработать.

---